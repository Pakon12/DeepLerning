{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#:ทดสอบเชื่อมต่อ **Feedforward Backpropagation** และใช้Activation function รวมกับ Optimizer และ L1-L2 regularization\n",
        "#วันที่ 18/07/2023\n",
        "# ฝึกทำโดย ***หยางคุณ***"
      ],
      "metadata": {
        "id": "RrJ7Uc4B_Y5E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "bwevTQ21EfhT"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class FFBP:\n",
        "    def __init__(self, learning_rate=0.001, num_epochs=30, batch_size=64, hidden_units=256, l1=0.0, l2=0.0):\n",
        "        # Convert target variable to one-hot encoding ค่าตัวแปรเป้าหมายที่เป็นหมายเลขหรือประเภทหนึ่งให้เป็นรหัสแบบทวิตแบบเวกเตอร์\n",
        "        self.num_classes = 10\n",
        "\n",
        "        # กำหนดค่าและปรับเพื่อปรับปรุงประสิทธิภาพของการเรียนรู้ของระบบ  Set hyperparameters\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_epochs = num_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.hidden_units = hidden_units\n",
        "        self.l1 = l1\n",
        "        self.l2 = l2\n",
        "        self.beta1 = 0.9\n",
        "        self.beta2 = 0.999\n",
        "        self.epsilon = 1e-8\n",
        "\n",
        "        # กำหนดค่าเริ่มต้น Initialize weights and biases\n",
        "        np.random.seed(0)\n",
        "        self.W1 = None #จุดนี้แสดงให้เห็นว่าตัวแปรถูกกำหนดค่าเริ่มต้นเป็น None ซึ่งหมายถึงว่ายังไม่มีค่าใดๆ ให้กับตัวแปรนี้\n",
        "        self.b1 = None\n",
        "        self.W2 = None\n",
        "        self.b2 = None\n",
        "\n",
        "        # กำหนดค่าเริ่มต้น Initialize Adam parameters\n",
        "        self.mW1 = None #จุดนี้แสดงให้เห็นว่าตัวแปรถูกกำหนดค่าเริ่มต้นเป็น None ซึ่งหมายถึงว่ายังไม่มีค่าใดๆ ให้กับตัวแปรนี้\n",
        "        self.mb1 = None\n",
        "        self.mW2 = None\n",
        "        self.mb2 = None\n",
        "        self.vW1 = None\n",
        "        self.vb1 = None\n",
        "        self.vW2 = None\n",
        "        self.vb2 = None\n",
        "\n",
        "        self.loss = []\n",
        "\n",
        "    # Activation function\n",
        "    def relu(self, x):\n",
        "        return np.maximum(0, x)\n",
        "\n",
        "    def softmax(self, x):\n",
        "        exps = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
        "        return exps / np.sum(exps, axis=1, keepdims=True)\n",
        "\n",
        "    # function ที่ปรับค่า weights and biases Optimizer parameters\n",
        "    def adam(self):\n",
        "        self.mW2 = self.beta1 * self.mW2 + (1 - self.beta1) * self.grad_W2\n",
        "        self.mb2 = self.beta1 * self.mb2 + (1 - self.beta1) * self.grad_b2\n",
        "        self.mW1 = self.beta1 * self.mW1 + (1 - self.beta1) * self.grad_W1\n",
        "        self.mb1 = self.beta1 * self.mb1 + (1 - self.beta1) * self.grad_b1\n",
        "\n",
        "        self.vW2 = self.beta2 * self.vW2 + (1 - self.beta2) * np.square(self.grad_W2)\n",
        "        self.vb2 = self.beta2 * self.vb2 + (1 - self.beta2) * np.square(self.grad_b2)\n",
        "        self.vW1 = self.beta2 * self.vW1 + (1 - self.beta2) * np.square(self.grad_W1)\n",
        "        self.vb1 = self.beta2 * self.vb1 + (1 - self.beta2) * np.square(self.grad_b1)\n",
        "\n",
        "        mW2_hat = self.mW2 / (1 - self.beta1 ** (self.epoch + 1))\n",
        "        mb2_hat = self.mb2 / (1 - self.beta1 ** (self.epoch + 1))\n",
        "        mW1_hat = self.mW1 / (1 - self.beta1 ** (self.epoch + 1))\n",
        "        mb1_hat = self.mb1 / (1 - self.beta1 ** (self.epoch + 1))\n",
        "\n",
        "        vW2_hat = self.vW2 / (1 - self.beta2 ** (self.epoch + 1))\n",
        "        vb2_hat = self.vb2 / (1 - self.beta2 ** (self.epoch + 1))\n",
        "        vW1_hat = self.vW1 / (1 - self.beta2 ** (self.epoch + 1))\n",
        "        vb1_hat = self.vb1 / (1 - self.beta2 ** (self.epoch + 1))\n",
        "\n",
        "        self.W2 -= self.learning_rate * mW2_hat / (np.sqrt(vW2_hat) + self.epsilon)\n",
        "        self.b2 -= self.learning_rate * mb2_hat / (np.sqrt(vb2_hat) + self.epsilon)\n",
        "        self.W1 -= self.learning_rate * mW1_hat / (np.sqrt(vW1_hat) + self.epsilon)\n",
        "        self.b1 -= self.learning_rate * mb1_hat / (np.sqrt(vb1_hat) + self.epsilon)\n",
        "\n",
        "    def rmsprop(self):\n",
        "        self.vW2 = self.beta1 * self.vW2 + (1 - self.beta1) * np.square(self.grad_W2)\n",
        "        self.vb2 = self.beta1 * self.vb2 + (1 - self.beta1) * np.square(self.grad_b2)\n",
        "        self.vW1 = self.beta1 * self.vW1 + (1 - self.beta1) * np.square(self.grad_W1)\n",
        "        self.vb1 = self.beta1 * self.vb1 + (1 - self.beta1) * np.square(self.grad_b1)\n",
        "\n",
        "        self.W2 -= self.learning_rate * self.grad_W2 / (np.sqrt(self.vW2) + self.epsilon)\n",
        "        self.b2 -= self.learning_rate * self.grad_b2 / (np.sqrt(self.vb2) + self.epsilon)\n",
        "        self.W1 -= self.learning_rate * self.grad_W1 / (np.sqrt(self.vW1) + self.epsilon)\n",
        "        self.b1 -= self.learning_rate * self.grad_b1 / (np.sqrt(self.vb1) + self.epsilon)\n",
        "\n",
        "\n",
        "    # fit เป็นเมธอดที่ใช้ในการฝึก (train) โมเดลเครื่องมือการเรียนรู้ (machine learning)\n",
        "    def fit(self, X_train, y_train, X_test, y_test, adam=False, rmsprop=False):\n",
        "        self.num_classes = np.max(y_train) + 1\n",
        "        self.y_train_encoded = np.eye(self.num_classes)[y_train]\n",
        "\n",
        "        # กำหนดค่าในการเริ้มปับค่า Initialize weights and biases\n",
        "        input_size = X_train.shape[1]\n",
        "        output_size = self.num_classes\n",
        "        self.W1 = np.random.randn(input_size, self.hidden_units)\n",
        "        self.b1 = np.zeros(self.hidden_units)\n",
        "        self.W2 = np.random.randn(self.hidden_units, output_size)\n",
        "        self.b2 = np.zeros(output_size)\n",
        "\n",
        "        # กำหนดค่าในการเริ่มปรับแต่งค่า Initialize Adam parameters\n",
        "        self.mW1 = np.zeros_like(self.W1) # คือการสร้างตัวแปร mW1 ที่มีค่าเป็นศูนย์ (zeros) และมีขนาดเท่ากับตัวแปร W1 โดยใช้ฟังก์ชัน np.zeros_like() ในการสร้างตัวแปรใหม่ที่มีค่าเป็นศูนย์และมีขนาดเท่ากับตัวแปรที่กำหนดให้เป็นพารามิเตอร์\n",
        "        self.mb1 = np.zeros_like(self.b1) # คือการสร้างตัวแปร mฺb1 ที่มีค่าเป็นศูนย์ (zeros) และมีขนาดเท่ากับตัวแปร b1 โดยใช้ฟังก์ชัน np.zeros_like() ในการสร้างตัวแปรใหม่ที่มีค่าเป็นศูนย์และมีขนาดเท่ากับตัวแปรที่กำหนดให้เป็นพารามิเตอร์\n",
        "        self.mW2 = np.zeros_like(self.W2)\n",
        "        self.mb2 = np.zeros_like(self.b2)\n",
        "        self.vW1 = np.zeros_like(self.W1)\n",
        "        self.vb1 = np.zeros_like(self.b1)\n",
        "        self.vW2 = np.zeros_like(self.W2)\n",
        "        self.vb2 = np.zeros_like(self.b2)\n",
        "\n",
        "        # ลูปในการ Training loop\n",
        "        for epoch in range(self.num_epochs):\n",
        "            # Shuffle the data การ Shuffle ข้อมูลหมายถึงกระบวนการสลับลำดับข้อมูลในชุดข้อมูล\n",
        "            indices = np.random.permutation(X_train.shape[0])\n",
        "            X_train = X_train[indices]\n",
        "            self.y_train_encoded = self.y_train_encoded[indices]\n",
        "\n",
        "            # Mini-batch gradient descent คือแนวคิดในการอัปเดตพารามิเตอร์ของโมเดลในขั้นตอนการฝึก (training) โดยแบ่งชุดข้อมูลฝึกออกเป็นส่วนย่อยๆ\n",
        "            num_batches = X_train.shape[0] // self.batch_size\n",
        "            for batch in range(num_batches):\n",
        "                # Extract mini-batch หมายถึงกระบวนการสกัดชุดข้อมูลย่อย (mini-batch) จากชุดข้อมูลทั้งหมด เพื่อนำไปใช้ในกระบวนการฝึกโมเดล\n",
        "                start = batch * self.batch_size\n",
        "                end = start + self.batch_size\n",
        "                X_batch = X_train[start:end]\n",
        "                y_batch = self.y_train_encoded[start:end]\n",
        "\n",
        "                # Forward propagation หมายถึงกระบวนการทำนายผลลัพธ์ของโมเดลจากข้อมูลนำเข้า (input) ไปยังข้อมูลผลลัพธ์ (output) โดยผ่านชั้นของโครงข่ายประสาทเทียม (neural network) ตามลำดับ\n",
        "                z1 = np.dot(X_batch, self.W1) + self.b1\n",
        "                a1 = self.relu(z1)\n",
        "                z2 = np.dot(a1, self.W2) + self.b2\n",
        "                output = self.softmax(z2)\n",
        "\n",
        "                # Backpropagation  \"การถอดรหัสย้อนกลับ\" เป็นกระบวนการในการคำนวณค่าเกรดของพารามิเตอร์ (weights) และปรับค่าพารามิเตอร์เหล่านั้นให้เหมาะสมในโครงข่ายประสาทเทียม (neural network) เพื่อให้โมเดลทำนายผลลัพธ์ที่ถูกต้องมากขึ้น\n",
        "                delta2 = output - y_batch\n",
        "                delta1 = np.dot(delta2, self.W2.T) * (a1 > 0)\n",
        "\n",
        "                # Compute gradients คำนวณค่าเกรด (gradient) ของพารามิเตอร์โครงข่ายประสาทเทียม (neural network) ในแต่ละชั้น เพื่อใช้ในกระบวนการปรับค่าพารามิเตอร์ให้เหมาะสมในการฝึกสอน (training) และทำนายผลลัพธ์ที่ถูกต้องมากขึ้น\n",
        "                grad_W2 = np.dot(a1.T, delta2)\n",
        "                grad_b2 = np.sum(delta2, axis=0)\n",
        "                grad_W1 = np.dot(X_batch.T, delta1)\n",
        "                grad_b1 = np.sum(delta1, axis=0)\n",
        "\n",
        "                # Add L1 and L2 regularization to gradients ป็นกระบวนการเพื่อลด overfitting และเพิ่มประสิทธิภาพของโมเดลในการฝึกสอน (training)\n",
        "                grad_W2 += self.l1 * np.sign(self.W2) + self.l2 * self.W2\n",
        "                grad_W1 += self.l1 * np.sign(self.W1) + self.l2 * self.W1\n",
        "\n",
        "                self.grad_W2 = grad_W2\n",
        "                self.grad_b2 = grad_b2\n",
        "                self.grad_W1 = grad_W1\n",
        "                self.grad_b1 = grad_b1\n",
        "                self.epoch = epoch\n",
        "\n",
        "                if adam:\n",
        "                    # Update parameters with Adam ปรับค่าด้วย adam optimizer\n",
        "                    self.adam()\n",
        "\n",
        "                if rmsprop:\n",
        "                    # Update parameters with RMSProp ปรับค่าด้วย RMSProp optimizer\n",
        "                    self.rmsprop()\n",
        "\n",
        "            # Evaluate accuracy on test set การประเมินความแม่นยำ (accuracy) บนชุดข้อมูลทดสอบ (test set) เป็นกระบวนการที่ใช้โมเดลที่ฝึกสอนแล้วในการทำนายผลลัพธ์บนชุดข้อมูลทดสอบ เพื่อวัดประสิทธิภาพของโมเดลที่ฝึกสอน\n",
        "            z1 = np.dot(X_test, self.W1) + self.b1\n",
        "            a1 = self.relu(z1)\n",
        "            z2 = np.dot(a1, self.W2) + self.b2\n",
        "            output = self.softmax(z2)\n",
        "            y_pred = np.argmax(output, axis=1)\n",
        "            accuracy = np.mean(y_pred == y_test)\n",
        "            print(f\"Epoch {epoch + 1} Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    #เป็นกระบวนการใช้โมเดลที่ฝึกสอนแล้วในการทำนายผลลัพธ์หรือค่าเป้าหมายของข้อมูลใหม่ที่ไม่เคยเห็นมาก่อน\n",
        "    def predict(self, X):\n",
        "        z1 = np.dot(X, self.W1) + self.b1\n",
        "        a1 = self.relu(z1)\n",
        "        z2 = np.dot(a1, self.W2) + self.b2\n",
        "        output = self.softmax(z2)\n",
        "        return np.argmax(output, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# โหลดข้อมูล MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train / 255.0 # การทำการปรับค่าข้อมูลในชุดข้อมูล X_train เพื่อทำให้ค่าข้อมูลอยู่ในช่วงระหว่าง 0 ถึง 1 หรือในรูปแบบที่สามารถจัดการได้ง่ายกับโมเดลการเรียนรู้เชิงลึก (Deep Learning)\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "X_train = X_train.reshape(60000, 784)\n",
        "X_test = X_test.reshape(10000, 784)"
      ],
      "metadata": {
        "id": "QTteK9y9IWCO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#เริ่มทำการ train model แบบใช้ adam Optimizer\n",
        "model = FFBP()\n",
        "model.fit(X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test,adam=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwUPBn15Gn94",
        "outputId": "6ac9238a-e329-42a0-cc5e-f69557dcd2ca"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Accuracy: 0.8511\n",
            "Epoch 2 Accuracy: 0.8745\n",
            "Epoch 3 Accuracy: 0.8854\n",
            "Epoch 4 Accuracy: 0.8935\n",
            "Epoch 5 Accuracy: 0.8986\n",
            "Epoch 6 Accuracy: 0.9048\n",
            "Epoch 7 Accuracy: 0.9063\n",
            "Epoch 8 Accuracy: 0.9110\n",
            "Epoch 9 Accuracy: 0.9126\n",
            "Epoch 10 Accuracy: 0.9143\n",
            "Epoch 11 Accuracy: 0.9180\n",
            "Epoch 12 Accuracy: 0.9204\n",
            "Epoch 13 Accuracy: 0.9217\n",
            "Epoch 14 Accuracy: 0.9218\n",
            "Epoch 15 Accuracy: 0.9232\n",
            "Epoch 16 Accuracy: 0.9245\n",
            "Epoch 17 Accuracy: 0.9258\n",
            "Epoch 18 Accuracy: 0.9259\n",
            "Epoch 19 Accuracy: 0.9271\n",
            "Epoch 20 Accuracy: 0.9284\n",
            "Epoch 21 Accuracy: 0.9290\n",
            "Epoch 22 Accuracy: 0.9302\n",
            "Epoch 23 Accuracy: 0.9311\n",
            "Epoch 24 Accuracy: 0.9317\n",
            "Epoch 25 Accuracy: 0.9318\n",
            "Epoch 26 Accuracy: 0.9326\n",
            "Epoch 27 Accuracy: 0.9337\n",
            "Epoch 28 Accuracy: 0.9342\n",
            "Epoch 29 Accuracy: 0.9339\n",
            "Epoch 30 Accuracy: 0.9333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#เริ่มทำการ train model แบบใช้ RMSprop Optimizer\n",
        "model = FFBP()\n",
        "model.fit(X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test,rmsprop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXxj8jLXsj-E",
        "outputId": "2ad57729-ad26-42ae-c310-ac8a0abb6f78"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Accuracy: 0.8847\n",
            "Epoch 2 Accuracy: 0.9089\n",
            "Epoch 3 Accuracy: 0.9215\n",
            "Epoch 4 Accuracy: 0.9265\n",
            "Epoch 5 Accuracy: 0.9328\n",
            "Epoch 6 Accuracy: 0.9377\n",
            "Epoch 7 Accuracy: 0.9415\n",
            "Epoch 8 Accuracy: 0.9447\n",
            "Epoch 9 Accuracy: 0.9442\n",
            "Epoch 10 Accuracy: 0.9459\n",
            "Epoch 11 Accuracy: 0.9487\n",
            "Epoch 12 Accuracy: 0.9475\n",
            "Epoch 13 Accuracy: 0.9501\n",
            "Epoch 14 Accuracy: 0.9491\n",
            "Epoch 15 Accuracy: 0.9496\n",
            "Epoch 16 Accuracy: 0.9527\n",
            "Epoch 17 Accuracy: 0.9536\n",
            "Epoch 18 Accuracy: 0.9544\n",
            "Epoch 19 Accuracy: 0.9534\n",
            "Epoch 20 Accuracy: 0.9547\n",
            "Epoch 21 Accuracy: 0.9519\n",
            "Epoch 22 Accuracy: 0.9549\n",
            "Epoch 23 Accuracy: 0.9540\n",
            "Epoch 24 Accuracy: 0.9515\n",
            "Epoch 25 Accuracy: 0.9545\n",
            "Epoch 26 Accuracy: 0.9556\n",
            "Epoch 27 Accuracy: 0.9544\n",
            "Epoch 28 Accuracy: 0.9554\n",
            "Epoch 29 Accuracy: 0.9542\n",
            "Epoch 30 Accuracy: 0.9566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "predictions = model.predict(X_test) #คือการทำนายผลลัพธ์โดยใช้โมเดลที่ถูกฝึกสอนด้วยข้อมูลฝึกสอน เมื่อให้โมเดลรับข้อมูลทดสอบ\n",
        "\n",
        "image = np.reshape(X_test[0], (28, 28)) #เพื่อทำการแปลงข้อมูลรูปภาพของตัวอย่างแรกใน X_test ให้อยู่ในรูปแบบของภาพที่มีขนาด 28x28 pixels\n",
        "\n",
        "plt.imshow(image, cmap='gray') #สำหรับแสดงรูปภาพที่ได้จากข้อมูล image โดยใช้คำสั่ง imshow โดยกำหนด cmap='gray' เพื่อให้แสดงผลเป็นสีเทา\n",
        "plt.title(f\"Label: {predictions[0]}\") #สำหรับแสดงรูปภาพที่ได้จากข้อมูล image โดยใช้คำสั่ง imshow โดยกำหนด cmap='gray' เพื่อให้แสดงผลเป็นสีเทา\n",
        "plt.show() #ใช้สำหรับแสดงกราฟที่ถูกสร้างขึ้นด้วยคำสั่งก่อนหน้านี้\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "DaZYo_z7IAIv",
        "outputId": "6fae69f9-cc13-4262-c322-826684a0d7a9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}